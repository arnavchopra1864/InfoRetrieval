{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1: 0.027873992919921875 MB\n",
      "Length: 14577\n",
      "\n",
      "Result 2: 0.018556594848632812 MB\n",
      "Length: 9692\n",
      "\n",
      "Result 3: 0.022190093994140625 MB\n",
      "Length: 11597\n",
      "\n",
      "Result 4: 0.025040626525878906 MB\n",
      "Length: 26208\n",
      "\n",
      "Result 5: 0.021535873413085938 MB\n",
      "Length: 11254\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'what are llms',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': None,\n",
       " 'results': [{'title': 'What are LLMs, and how are they used in generative AI?',\n",
       "   'url': 'https://www.computerworld.com/article/1627101/what-are-large-language-models-and-how-are-they-used-in-generative-ai.html',\n",
       "   'content': 'LLMs are controlled by parameters, as in millions, billions, and even trillions of them. (Think of a parameter as something that helps an LLM decide between different answer choices.)',\n",
       "   'score': 0.97196,\n",
       "   'raw_content': \"About\\nPolicies\\nOur Network\\nMore\\nAmericas\\nAsia\\nEurope\\nOceania\\nTopics\\nAbout\\nPolicies\\nOur Network\\nMore\\nWhat are LLMs, and how are they used in generative AI?\\nLarge language models are the algorithmic basis for chatbots like OpenAI's ChatGPT and Google's Bard. The technology is tied back to billions — even trillions — of parameters that can make them both inaccurate and non-specific for vertical industry use. Here's what LLMs are and how they work.\\nWhen ChatGPT arrived in November 2022, it made mainstream the idea that generative artificial intelligence (genAI) could be used by companies and consumers to automate tasks, help with creative ideas, and even code software.\\nIf you need to boil down an email or chat thread into a concise summary, a chatbot such as OpenAI’s ChatGPT or Google’s Bard can do that. If you need to spruce up your resume with more eloquent language and impressive bullet points, AI can help. Want some ideas for a new marketing or ad campaign? Generative AI to the rescue.\\nChatGPT stands for chatbot generative pre-trained transformer. The chatbot’s foundation is the GPT large language model (LLM), a computer algorithm that processes natural language inputs and predicts the next word based on what it’s already seen. Then it predicts the next word, and the next word, and so on until its answer is complete.\\nIn the simplest of terms, LLMs are next-word prediction engines.\\nAlong with OpenAI’s GPT-3 and 4 LLM, popular LLMs include open models such as Google’s LaMDA\\xa0and\\xa0PaLM\\xa0LLM (the basis for Bard),\\xa0Hugging Face’s BLOOM\\xa0and\\xa0XLM-RoBERTa,\\xa0Nvidia’s NeMO LLM,\\xa0XLNet,\\xa0Co:here, and\\xa0GLM-130B.\\nOpen-source LLMs, in particular, are gaining traction, enabling a cadre of developers to create more customizable models at a lower cost. Meta’s February launch of LLaMA (Large Language Model Meta AI) kicked off an explosion among developers looking to build on top of open-source LLMs.\\nLLMs are a\\xa0type of AI that are currently trained on a massive trove of articles, Wikipedia entries, books, internet-based resources and other input to produce human-like responses to natural\\xa0language\\xa0queries. That’s an immense amount of data. But LLMs are poised to shrink, not grow, as vendors seek to customize them for specific uses that don’t need the massive data sets used by today’s most popular models.\\nFor example, Google’s new PaLM 2 LLM, announced earlier this month, uses almost five times more training data than its predecessor of just a year ago — 3.6 trillion tokens or strings of words,\\xa0according to one report. The additional datasets allow PaLM 2 to perform more advanced coding, math, and creative writing tasks.\\nTraining up an LLM right requires massive server farms, or supercomputers, with enough compute power to tackle billions of parameters.\\nSo, what is an LLM?\\nAn LLM is a machine-learning neuro network trained through data input/output sets; frequently, the text is unlabeled or uncategorized, and the model is using self-supervised or semi-supervised learning methodology. Information is ingested, or content entered, into the LLM, and the output is what that algorithm predicts the next word will be. The input can be proprietary corporate data or, as in the case of ChatGPT, whatever data it’s fed and scraped directly from the internet.\\nTraining LLMs to use the right data requires the use of massive, expensive server farms that act as supercomputers.\\nLLMs are controlled by parameters, as in millions, billions, and even trillions of them. (Think of a parameter as something that helps an LLM decide between different answer choices.)\\xa0OpenAI’s GPT-3 LLM has 175 billion parameters, and the company’s latest model – GPT-4 – is purported to have\\xa01 trillion\\xa0parameters.\\nFor example, you could type into an LLM prompt window “For lunch today I ate….” The LLM could come back with “cereal,” or “rice,” or “steak tartare.” There’s no 100% right answer, but there is a probability based on the data already ingested in the model. The answer “cereal” might be the most probable answer based on existing data, so the LLM could complete the sentence with that word. But, because the LLM is a probability engine, it assigns a percentage to each possible answer. Cereal might occur 50% of the time, “rice” could be the answer 20% of the time, steak tartare .005% of the time.\\n“The point is it learns to do this,” said Yoon Kim, an assistant professor at\\xa0MIT who studies Machine Learning, Natural Language Processing and Deep Learning. “It’s not like a human — a large enough training set will assign these probabilities.”\\nBut beware — junk in, junk out. In other words, if the information an LLM has ingested is biased, incomplete, or otherwise undesirable, then the response it gives could be equally unreliable, bizarre, or even offensive. When a response goes off the rails, data analysts refer to it as “hallucinations,” because they can be so far off track.\\n“Hallucinations happen because LLMs, in their in most vanilla form, don’t have an internal state representation of the world,” said Jonathan Siddharth, CEO of Turing, a Palo Alto, California company that uses AI to find, hire, and onboard software engineers remotely. “There’s no concept of fact. They’re predicting the next word based on what they’ve seen so far — it’s a statistical estimate.”\\nBecause some LLMs also train themselves on internet-based data, they can move well beyond what their initial developers created them to do. For example, Microsoft’s Bing uses GPT-3 as its basis, but it’s also querying a search engine and analyzing the first 20 results or so. It uses both an LLM and the internet to offer responses.\\n“We see things like a model being trained on one programming language and these models then automatically generate code in another programming language it has never seen,” Siddharth said. “Even natural language; it’s not trained on French, but it’s able to generate sentences in French.”\\n“It’s almost like there’s some emergent behavior. We don’t know quite know how these neural network works,” he added. “It’s both scary and exciting at the same time.”\\nAnother problem with LLMs and their parameters is the unintended biases that can be introduced by LLM developers and self-supervised data collection from the internet.\\nAre LLMs biased?\\nFor example, systems like ChatGPT are highly likely to provide gender-biased answers based on the data they’ve ingested from the internet and programmers, according to Sayash Kapoor, a Ph.D. candidate at Princeton University’s Center for Information Technology Policy.\\n“We tested ChatGPT for biases that are implicit — that is, the gender of the person is not obviously mentioned, but only included as information about their pronouns,” Kapoor said. “That is, if we replace “she” in the sentence with “he,” ChatGPT would be three times less likely to make an error.”\\nInnate biases can be dangerous, Kapoor said, if language models are used in consequential real-world settings. For example, if biased language models are used in hiring processes, they can lead to real-world gender bias.\\nSuch biases are not a result of developers intentionally programming their models to be biased. But ultimately, the responsibility for fixing the biases rests with the developers, because they’re the ones releasing and profiting from AI models, Kapoor argued.\\nWhat is prompt engineering?\\nWhile most LLMs, such as OpenAI’s GPT-4, are pre-filled with massive amounts of information, prompt engineering\\xa0by users can also train the model for specific industry or even organizational use.\\n“Prompt engineering is about deciding what we feed this algorithm so that it says what we want it to,” MIT’s Kim said. “The LLM is a system that just babbles without any text context. In some sense of the term, an LLM is already a chatbot.”\\nPrompt engineering is the process of crafting and optimizing text prompts for an LLM to achieve desired outcomes. Perhaps as important for users, prompt engineering is poised to become a vital skill for IT and business professionals.\\nBecause prompt engineering is a nascent and emerging discipline, enterprises are relying on booklets and prompt guides as a way to ensure optimal responses from their AI applications. There are even marketplaces emerging for prompts, such as the\\xa0100 best prompts for ChatGPT.\\nPerhaps as important for users, prompt engineering is poised to become a vital skill for IT and business professionals, according to Eno Reyes, a machine learning engineer with Hugging Face, a community-driven platform that creates and hosts LLMs. Prompt engineers will be responsible for creating customized LLMs for business use.\\nHow will LLMs become smaller, faster, and cheaper?\\nToday, chatbots based on LLMs are most commonly used “out of the box” as a text-based,\\xa0web-chat interface. They’re used in search engines such as Google’s Bard and Microsoft’s Bing (based on ChatGPT) and for automated online customer assistance. Companies can ingest their own datasets to make the chatbots more customized for their particular business, but accuracy can suffer because of the massive trove of data already ingested.\\n“What we’re discovering more and more is that with small models that you train on more data longer…, they can do what large models used to do,” Thomas Wolf, co-founder and CSO at Hugging Face, said while attending an MIT conference earlier this month. “I think we’re maturing basically in how we understand what’s happening there.\\n“There’s this first step where you try everything to get this first part of something working, and then you’re in the phase where you’re trying to…be efficient and less costly to run,” Wolf said. “It’s not enough to just scrub the whole web, which is what everyone has been doing. It’s much more important to have quality data.”\\nLLMs can cost from a couple of million dollars to $10 million to train for specific use cases, depending on their size and purpose.\\nWhen LLMs focus their AI and compute power on smaller datasets, however, they perform as well or better than the enormous LLMs that rely on massive, amorphous data sets. They can also be more accurate in creating the content users seek — and they’re much cheaper to train.\\nEric Boyd, corporate vice president of AI Platforms at Microsoft, recently spoke at the MIT EmTech conference and said when his company first began working on AI image models with OpenAI four years ago, performance would plateau as the datasets grew in size. Language models, however, had far more capacity to ingest data without a performance slowdown.\\nMicrosoft, the largest financial backer of OpenAI and ChatGPT, invested in the infrastructure to build larger LLMs. “So, we’re figuring out now how to get similar performance without having to have such a large model,” Boyd said. “Given more data, compute and training time, you are still able to find more performance, but there are also a lot of techniques we’re now learning for how we don’t have to make them quite so large and are able to manage them more efficiently.\\n“That’s super important because…these things are very expensive. If we want to have broad adoption for them, we’re going to have to figure how the costs of both training them and serving them,” Boyd said.\\nFor example, when a user submits a prompt to GPT-3, it must access all 175 billion\\xa0of its parameters\\xa0to deliver an answer. One method for creating smaller LLMs, known as sparse expert models, is expected to reduce the training and computational costs for LLMs, “resulting in massive models with a better accuracy than their dense counterparts,” he said.\\nResearchers from Meta Platforms (formerly Facebook) believe sparse models can achieve performance similar to that of ChatGPT and other massive LLMs using “a fraction of the compute.”\\n“For models with relatively modest compute budgets, a sparse model can perform on par with a dense model that requires almost four times as much compute,” Meta said in an October 2022 research paper.\\nSmaller models are already being released by companies such as Aleph Alpha, Databricks, Fixie, LightOn, Stability AI, and even Open AI. The more agile LLMs have between a few billion and 100 billion parameters.\\nPrivacy, security issues still abound\\nWhile many users marvel at the remarkable capabilities of LLM-based chatbots, governments and consumers cannot turn a blind eye to the potential privacy issues lurking within, according to Gabriele Kaveckyte, privacy counsel at cybersecurity company Surfshark.\\nFor example, earlier this year, Italy became the first Western nation to ban further development of ChatGPT over privacy concerns. It later reversed that decision, but the initial ban occurred after the natural language processing app experienced a data breach involving user conversations and payment information.\\n“While some improvements have been made by ChatGPT following Italy’s temporary ban, there is still room for improvement,” Kaveckyte said. “Addressing these potential privacy issues is crucial to ensure the responsible and ethical use of data, fostering trust, and safeguarding user privacy in AI interactions.”\\nKaveckyte analyzed ChatGPT’s data collection practices, for instance, and developed a list of potential flaws: it collected a massive amount of personal data to train its models, but may have had\\xa0no legal basis for doing so; it didn’t notify all of the people whose data was used\\xa0to train the AI model; it’s not always accurate; and it lacks effective age verification tools\\xa0to prevent children under 13 from using it.\\nAlong with those issues, other experts are concerned there are more basic problems LLMs have yet to overcome — namely the security of data collected and stored by the AI, intellectual property theft, and data confidentiality.\\n“For a hospital or a bank to be able to use LLMs, we’re doing to have to solve [intellectual property], security, [and] confidentiality issues,” Turing’s Siddharth said. “There are good engineering solutions for some of these. And I think those will get solved, but those need to be solved in order for them to be used in enterprises. Companies don’t want to use an LLM in a context where it uses the company’s data to help deliver better results to a competitor.”\\nNot surprisingly, a number of nations and government agencies around the globe have launched efforts to deal with AI tools, with China being the most proactive so far. Among those efforts:\\nRelated content\\nFrom our editors straight to your inbox\\nSenior Reporter Lucas Mearian covers AI in the enterprise, Future of Work issues, healthcare IT and FinTech.\\nMore from this author\\nMost popular authors\"},\n",
       "  {'title': 'What Are Large Language Models (LLMs)? | IBM',\n",
       "   'url': 'https://www.ibm.com/topics/large-language-models',\n",
       "   'content': 'AI governance and traceability are also fundamental aspects of the solutions IBM brings to its customers, so that activities that involve AI are managed and monitored to allow for tracing origins, data and models in a way that is always auditable and accountable.\\n LLMs have become a household name thanks to the role they have played in bringing generative AI to the forefront of the public interest, as well as the point on which organizations are focusing to adopt artificial intelligence across numerous business functions and use cases.\\n Large language models (LLMs) are a category of foundation models trained on immense amounts of data making them capable of understanding and generating natural language and other types of content to perform a wide range of tasks.\\n This is in stark contrast to the idea of building and training domain specific models for each of these use cases individually, which is prohibitive under many criteria (most importantly cost and infrastructure), stifles synergies and can even lead to inferior performance.\\n In a nutshell, LLMs are designed to understand and generate text like a human, in addition to other forms of content, based on the vast amount of data used to train them.',\n",
       "   'score': 0.9433,\n",
       "   'raw_content': \"Large language models (LLMs) are a category of foundation models trained on immense amounts of data making them capable of understanding and generating natural language and other types of content to perform a wide range of tasks.\\nLLMs have become a household name thanks to the role they have played in bringing generative AI to the forefront of the public interest, as well as the point on which organizations are focusing to adopt artificial intelligence across numerous business functions and use cases.\\nOutside of the enterprise context, it may seem like LLMs have arrived out of the blue along with new developments in generative AI. However, many companies, including IBM, have spent years implementing LLMs at different levels to enhance their natural language understanding (NLU) and natural language processing (NLP) capabilities. This has occurred alongside advances in machine learning, machine learning models, algorithms, neural networks and the transformer models that provide the architecture for these AI systems.\\nLLMs are a class of foundation models, which are trained on enormous amounts of data to provide the foundational capabilities needed to drive multiple use cases and applications, as well as resolve a multitude of tasks. This is in stark contrast to the idea of building and training domain specific models for each of these use cases individually, which is prohibitive under many criteria (most importantly cost and infrastructure), stifles synergies and can even lead to inferior performance.\\nLLMs represent a significant breakthrough in NLP and artificial intelligence, and are easily accessible to the public through interfaces like Open AI’s Chat GPT-3 and GPT-4, which have garnered the support of Microsoft. Other examples include Meta’s Llama models and Google’s bidirectional encoder representations from transformers (BERT/RoBERTa) and PaLM models. IBM has also recently launched its Granite model series on watsonx.ai, which has become the generative AI backbone for other IBM products like watsonx Assistant and watsonx Orchestrate.\\nIn a nutshell, LLMs are designed to understand and generate text like a human, in addition to other forms of content, based on the vast amount of data used to train them. They have the ability to infer from context, generate coherent and contextually relevant responses, translate to languages other than English, summarize text, answer questions (general conversation and FAQs) and even assist in creative writing or code generation tasks.\\nThey are able to do this thanks to billions of parameters that enable them to capture intricate patterns in language and perform a wide array of language-related tasks. LLMs are revolutionizing applications in various fields, from chatbots and virtual assistants to content generation, research assistance and language translation.\\nAs they continue to evolve and improve, LLMs are poised to reshape the way we interact with technology and access information, making them a pivotal part of the modern digital landscape.\\nMultiply the power of AI for your enterprise with IBM’s next-generation AI and data platform.\\nSubscribe to the IBM newsletter\\nLLMs operate by leveraging deep learning techniques and vast amounts of textual data. These models are typically based on a transformer architecture, like the generative pre-trained transformer, which excels at handling sequential data like text input. LLMs consist of multiple layers of neural networks, each with parameters that can be fine-tuned during training, which are enhanced further by a numerous layer known as the attention mechanism, which dials in on specific parts of data sets.\\nDuring the training process, these models learn to predict the next word in a sentence based on the context provided by the preceding words. The model does this through attributing a probability score to the recurrence of words that have been tokenized— broken down into smaller sequences of characters. These tokens are then transformed into embeddings, which are numeric representations of this context.\\nTo ensure accuracy, this process involves training the LLM on a massive corpora of text (in the billions of pages), allowing it to learn grammar, semantics and conceptual relationships through zero-shot and self-supervised learning. Once trained on this training data, LLMs can generate text by autonomously predicting the next word based on the input they receive, and drawing on the patterns and knowledge they've acquired. The result is coherent and contextually relevant language generation that can be harnessed for a wide range of NLU and content generation tasks.\\nModel performance can also be increased through prompt engineering, prompt-tuning, fine-tuning and other tactics like reinforcement learning with human feedback (RLHF) to remove the biases, hateful speech and factually incorrect answers known as “hallucinations” that are often unwanted byproducts of training on so much unstructured data. This is one of the most important aspects of ensuring enterprise-grade LLMs are ready for use and do not expose organizations to unwanted liability, or cause damage to their reputation.\\nLLMs are redefining an increasing number of business processes and have proven their versatility across a myriad of use cases and tasks in various industries. They augment conversational AI in chatbots and virtual assistants (like IBM watsonx Assistant and Google’s BARD) to enhance the interactions that underpin excellence in customer care, providing context-aware responses that mimic interactions with human agents.\\nLLMs also excel in content generation, automating content creation for blog articles, marketing or sales materials and other writing tasks. In research and academia, they aid in summarizing and extracting information from vast datasets, accelerating knowledge discovery. LLMs also play a vital role in language translation, breaking down language barriers by providing accurate and contextually relevant translations. They can even be used to write code, or “translate” between programming languages.\\nMoreover, they contribute to accessibility by assisting individuals with disabilities, including text-to-speech applications and generating content in accessible formats. From healthcare to finance, LLMs are transforming industries by streamlining processes, improving customer experiences and enabling more efficient and data-driven decision making.\\nMost excitingly, all of these capabilities are easy to access, in some cases literally an API integration away.\\nHere is a list of some of the most important areas where LLMs benefit organizations:\\nText generation: language generation abilities, such as writing emails, blog posts or other mid-to-long form content in response to prompts that can be refined and polished. An excellent example is retrieval-augmented generation (RAG).\\nContent summarization: summarize long articles, news stories, research reports, corporate documentation and even customer history into thorough texts tailored in length to the output format.\\nAI assistants: chatbots that answer customer queries, perform backend tasks and provide detailed information in natural language as a part of an integrated, self-serve customer care solution.\\nCode generation: assists developers in building applications, finding errors in code and uncovering security issues in multiple programming languages, even “translating” between them.\\nSentiment analysis: analyze text to determine the customer’s tone in order understand customer feedback at scale and aid in brand reputation management.\\nLanguage translation: provides wider coverage to organizations across languages and geographies with fluent translations and multilingual capabilities.\\nLLMs stand to impact every industry, from finance to insurance, human resources to healthcare and beyond, by automating customer self-service, accelerating response times on an increasing number of tasks as well as providing greater accuracy, enhanced routing and intelligent context gathering.\\nOrganizations need a solid foundation in governance practices to harness the potential of AI models to revolutionize the way they do business. This means providing access to AI tools and technology that is trustworthy, transparent, responsible and secure. AI governance and traceability are also fundamental aspects of the solutions IBM brings to its customers, so that activities that involve AI are managed and monitored to allow for tracing origins, data and models in a way that is always auditable and accountable.\\nTrained on enterprise-focused datasets curated directly by IBM to help mitigate the risks that come with generative AI, so that models are deployed responsibly and require minimal input to ensure they are customer ready.\\nWatsonx.ai provides access to open-source models from Hugging Face, third party models as well as IBM’s family of pre-trained models. The Granite model series, for example, uses a decoder architecture to support a variety of generative AI tasks targeted for enterprise use cases.\\nDeliver exceptional experiences to customers at every interaction, call center agents that need assistance, and even employees who need information. Scale answers in natural language grounded in business content to drive outcome-oriented interactions and fast, accurate responses.\\nAutomate tasks and simplify complex processes, so that employees\\xa0can focus on more high-value, strategic work, all from a conversational interface that\\xa0augments employee productivity levels with a suite of automations and AI tools.\\nLearn more about watsonx and how to multiply the power of AI for your enterprise with IBM’s next-generation AI and data platform.\"},\n",
       "  {'title': 'What are Large Language Models? | Definition from TechTarget',\n",
       "   'url': 'https://www.techtarget.com/whatis/definition/large-language-model-LLM',\n",
       "   'content': \"Process mining is a technique that interprets logs from enterprise applications -- like customer resource management (CRM) and ...\\nOrganizational change management (OCM) is a type of change management framework for managing the effect of new business processes...\\nAn employee resource group is a workplace club or more formally realized affinity group organized around a shared interest or ...\\nEmployee training and development is a set of activities and programs designed to enhance the knowledge, skills and abilities of ...\\nEmployee sentiment analysis is the use of natural language processing and other AI techniques to automatically analyze employee ...\\nCustomer profiling is the detailed and systematic process of constructing a clear portrait of a company's ideal customer by ...\\nCustomer insight, also known as consumer insight, is the understanding and interpretation of customer data, behaviors and ...\\n Among the common types are the following:\\nFor more on generative AI, read the following articles:\\nGenerative AI challenges that businesses should consider\\nGenerative AI ethics: 8 biggest concerns\\nGenerative AI landscape: Potential future trends\\nHistory of generative AI innovations spans 9 decades\\nHow to detect AI-generated content\\nThe future of large language models\\nThe future of LLMs is still being written by the humans who are developing the technology, though there could be a future in which the LLMs write themselves, too. The possession factor, in a security context, is a category of user authentication credentials based on items that the user has ...\\nA CISO as a service (CISOaaS) is the outsourcing of CISO (chief information security officer) and information security leadership...\\nCyber hygiene, or cybersecurity hygiene, is a set of practices individuals and organizations perform regularly to maintain the ...\\nRadical innovation is an invention that destroys or supplants an existing business model.\\n LLMs have become increasingly popular because they have broad applicability for a range of NLP tasks, including the following:\\nAmong the most common uses for conversational AI is through a chatbot, which can exist in any number of different forms where a user interacts in a query-and-response model. There's also a class of LLMs based on the concept known as retrieval-augmented generation -- including Google's Realm (short for Retrieval-Augmented Language Model) -- that will enable training and inference on a very specific corpus of data, much like how a user today can specifically search content on a single site.\\n\",\n",
       "   'score': 0.93677,\n",
       "   'raw_content': 'The potential of AI technology has been percolating in the background for years. But when ChatGPT, the AI chatbot, began grabbing headlines in early 2023, it put generative AI in the spotlight.\\nThis guide is your go-to manual for generative AI, covering its benefits, limits, use cases, prospects and much more.\\nYou forgot to provide an Email Address.\\nThis email address doesn’t appear to be valid.\\nThis email address is already registered. Please log in.\\nYou have exceeded the maximum character limit.\\nPlease provide a Corporate Email Address.\\nPlease check the box if you want to proceed.\\nPlease check the box if you want to proceed.\\nBy submitting my Email address I confirm that I have read and accepted the Terms of Use and Declaration of Consent.\\nlarge language models (LLMs)\\nWhat are large language models (LLMs)?\\nA large language model (LLM) is a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content. The term generative AI also is closely connected with LLMs, which are, in fact, a type of generative AI that has been specifically architected to help generate text-based content.\\nOver millennia, humans developed spoken languages to communicate. Language is at the core of all forms of human and technological communications; it provides the words, semantics and grammar needed to convey ideas and concepts. In the AI world, a language model serves a similar purpose, providing a basis to communicate and generate new concepts.\\nThe first AI language models trace their roots to the earliest days of AI. The Eliza language model debuted in 1966 at MIT and is one of the earliest examples of an AI language model. All language models are first trained on a set of data, and then they make use of various techniques to infer relationships and then generate new content based on the trained data. Language models are commonly used in natural language processing (NLP) applications where a user inputs a query in natural language to generate a result.\\nAn LLM is the evolution of the language model concept in AI that dramatically expands the data used for training and inference. In turn, it provides a massive increase in the capabilities of the AI model. While there isn\\'t a universally accepted figure for how large the data set for training needs to be, an LLM typically has at least one billion or more parameters. Parameters are a machine learning term for the variables present in the model on which it was trained that can be used to infer new content.\\nThis article is part of\\nWhat is generative AI? Everything you need to know\\nModern LLMs emerged in 2017 and use transformer models, which are neural networks commonly referred to as transformers. With a large number of parameters and the transformer model, LLMs are able to understand and generate accurate responses rapidly, which makes the AI technology broadly applicable across many different domains.\\nSome LLMs are referred to as foundation models, a term coined by the Stanford Institute for Human-Centered Artificial Intelligence in 2021. A foundation model is so large and impactful that it serves as the foundation for further optimizations and specific use cases.\\nWhy are LLMs becoming important to businesses?\\nAs AI continues to grow, its place in the business setting becomes increasingly dominant. This is shown through the use of LLMs as well as machine learning tools. In the process of composing and applying machine learning models, research advises that simplicity and consistency should be among the main goals. Identifying the issues that must be solved is also essential, as is comprehending historical data and ensuring accuracy.\\nThe benefits associated with machine learning are often grouped into four categories: efficiency, effectiveness, experience and business evolution. As these continue to emerge, businesses invest in this technology.\\nHow do large language models work?\\nLLMs take a complex approach that involves multiple components.\\nAt the foundational layer, an LLM needs to be trained on a large volume -- sometimes referred to as a corpus -- of data that is typically petabytes in size. The training can take multiple steps, usually starting with an unsupervised learning approach. In that approach, the model is trained on unstructured data and unlabeled data. The benefit of training on unlabeled data is that there is often vastly more data available. At this stage, the model begins to derive relationships between different words and concepts.\\nThe next step for some LLMs is training and fine-tuning with a form of self-supervised learning. Here, some data labeling has occurred, assisting the model to more accurately identify different concepts.\\nNext, the LLM undertakes deep learning as it goes through the transformer neural network process. The transformer model architecture enables the LLM to understand and recognize the relationships and connections between words and concepts using a self-attention mechanism. That mechanism is able to assign a score, commonly referred to as a weight, to a given item (called a token) in order to determine the relationship.\\nOnce an LLM has been trained, a base exists on which the AI can be used for practical purposes. By querying the LLM with a prompt, the AI model inference can generate a response, which could be an answer to a question, newly generated text, summarized text or a sentiment analysis report.\\nWhat are large language models used for?\\nLLMs have become increasingly popular because they have broad applicability for a range of NLP tasks, including the following:\\nAmong the most common uses for conversational AI is through a chatbot, which can exist in any number of different forms where a user interacts in a query-and-response model. The most widely used LLM-based AI chatbot is ChatGPT, which is developed by OpenAI. ChatGPT currently is based on the GPT-3.5 model, although paying subscribers can use the newer GPT-4 LLM.\\nWhat are the advantages of large language models?\\nThere are numerous advantages that LLMs provide to organizations and users:\\nWhat are the challenges and limitations of large language models?\\nWhile there are many advantages to using LLMs, there are also several challenges and limitations:\\nWhat are the different types of large language models?\\nThere is an evolving set of terms to describe the different types of large language models. Among the common types are the following:\\nFor more on generative AI, read the following articles:\\nGenerative AI challenges that businesses should consider\\nGenerative AI ethics: 8 biggest concerns\\nGenerative AI landscape: Potential future trends\\nHistory of generative AI innovations spans 9 decades\\nHow to detect AI-generated content\\nThe future of large language models\\nThe future of LLMs is still being written by the humans who are developing the technology, though there could be a future in which the LLMs write themselves, too. The next generation of LLMs will not likely be artificial general intelligence or sentient in any sense of the word, but they will continuously improve and get \"smarter.\"\\nLLMs will also continue to expand in terms of the business applications they can handle. Their ability to translate content across different contexts will grow further, likely making them more usable by business users with different levels of technical expertise..\\nLLMs will continue to be trained on ever larger sets of data, and that data will increasingly be better filtered for accuracy and potential bias, partly through the addition of fact-checking capabilities. It\\'s also likely that LLMs of the future will do a better job than the current generation when it comes to providing attribution and better explanations for how a given result was generated.\\nEnabling more accurate information through domain-specific LLMs developed for individual industries or functions is another possible direction for the future of large language models. Expanded use of techniques such as reinforcement learning from human feedback, which OpenAI uses to train ChatGPT, could help improve the accuracy of LLMs, too. There\\'s also a class of LLMs based on the concept known as retrieval-augmented generation -- including Google\\'s Realm (short for Retrieval-Augmented Language Model) -- that will enable training and inference on a very specific corpus of data, much like how a user today can specifically search content on a single site.\\nThere\\'s also ongoing work to optimize the overall size and training time required for LLMs, including development of Meta\\'s Llama model. Llama 2, which was released in July 2023, has less than half the parameters than GPT-3 has and a fraction of the number GPT-4 contains, though its backers claim it can be more accurate.\\nOn the other hand, the use of large language models could drive new instances of shadow IT in organizations. CIOs will need to implement usage guardrails and provide training to avoid data privacy problems and other issues. LLMs could also create new cybersecurity challenges by enabling attackers to write more persuasive and realistic phishing emails or other malicious communications.\\nNonetheless, the future of LLMs likely will remain bright as the technology continues to evolve in ways that help improve human productivity.\\nTechnology writer George Lawton contributed to this article.\\nBlockchain is a record-keeping technology designed to make it impossible to hack the system or forge the data stored on it, thereby making it secure and immutable.\\n5G standalone (5G SA) is a cellular infrastructure built specifically for 5G services by implementing 5G standards and protocols ...\\nCisco IOS (Internetwork Operating System) is a collection of proprietary operating systems (OSes) that runs on Cisco hardware ...\\n6G (sixth-generation wireless) is the successor to 5G cellular technology. 6G networks will be able to use higher frequencies ...\\nThe possession factor, in a security context, is a category of user authentication credentials based on items that the user has ...\\nA CISO as a service (CISOaaS) is the outsourcing of CISO (chief information security officer) and information security leadership...\\nCyber hygiene, or cybersecurity hygiene, is a set of practices individuals and organizations perform regularly to maintain the ...\\nRadical innovation is an invention that destroys or supplants an existing business model.\\nProcess mining is a technique that interprets logs from enterprise applications -- like customer resource management (CRM) and ...\\nOrganizational change management (OCM) is a type of change management framework for managing the effect of new business processes...\\nAn employee resource group is a workplace club or more formally realized affinity group organized around a shared interest or ...\\nEmployee training and development is a set of activities and programs designed to enhance the knowledge, skills and abilities of ...\\nEmployee sentiment analysis is the use of natural language processing and other AI techniques to automatically analyze employee ...\\nCustomer profiling is the detailed and systematic process of constructing a clear portrait of a company\\'s ideal customer by ...\\nCustomer insight, also known as consumer insight, is the understanding and interpretation of customer data, behaviors and ...\\nA buyer persona is a composite representation of a specific type of customer in a market segment.\\nAll Rights Reserved,\\nCopyright 1999 - 2023, TechTarget\\nPrivacy Policy\\nCookie Preferences\\nCookie Preferences\\nDo Not Sell or Share My Personal Information'},\n",
       "  {'title': 'Large language model - Wikipedia',\n",
       "   'url': 'https://en.wikipedia.org/wiki/Large_language_model',\n",
       "   'content': '\"[80][81]\\nIn contrast, some proponents of the \"LLMs lack understanding\" school believe that existing LLMs are \"simply remixing and recombining existing writing\",[79] or point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability.[75] For example, GPT-4 has natural deficits in planning and in real-time learning.[77] Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed \"hallucination\".[82] Specifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input.[83] Because of the rapid pace of improvement of large language models, evaluation benchmarks have suffered from short lifespans, with state of the art models quickly \"saturating\" existing benchmarks, exceeding the performance of human annotators, leading to efforts to replace or augment the benchmark with more challenging tasks.[88] In addition, there are cases of \"shortcut learning\" wherein AIs sometimes \"cheat\" on multiple-choice tests by using statistical correlations in superficial test question wording in order to guess the correct responses, without necessarily understanding the actual question being asked.[75]\\nSome datasets have been constructed adversarially, focusing on particular problems on which extant language models seem to have unusually poor performance compared to humans. The linguistic description of the environment given to the LLM planner can even be the LaTeX code of a paper describing the environment.[37]\\nIn the DEPS (\"Describe, Explain, Plan and Select\") method, an LLM is first connected to the visual world via image descriptions, then it is prompted to produce plans for complex tasks and behaviors based on its pretrained knowledge and environmental feedback it receives.[38]\\nThe Reflexion method[39] constructs an agent that learns over multiple episodes. One broad category of evaluation dataset is question answering datasets, consisting of pairs of questions and correct answers, for example, (\"Have the San Jose Sharks won the Stanley Cup?\", \"No\").[85] A question answering task is considered \"open book\" if the model\\'s prompt includes text from which the expected answer can be derived (for example, the previous question could be adjoined with some text which includes the sentence \"The Sharks have advanced to the Stanley Cup finals once, losing to the Pittsburgh Penguins in 2016.\"[85]). The authors considered a toy statistical model of an LLM solving multiple-choice questions, and showed that this statistical model, modified to account for other types of tasks, applies to these tasks as well.[70]\\nLet\\nx\\n{\\\\displaystyle x}\\nbe the number of parameter count, and\\ny\\n{\\\\displaystyle y}\\nbe the performance of the model.\\n',\n",
       "   'score': 0.92868,\n",
       "   'raw_content': 'Contents\\nLarge language model\\nA large language model (LLM) is a type of language model notable for its ability to achieve general-purpose language understanding and generation. LLMs acquire these abilities by using massive amounts of data to learn billions of parameters during training and consuming large computational resources during their training and operation.[1] LLMs are artificial neural networks (mainly transformers[2]) and are (pre-)trained using self-supervised learning and semi-supervised learning.\\nAs autoregressive language models, they work by taking an input text and repeatedly predicting the next token or word.[3] Up to 2020, fine tuning was the only way a model could be adapted to be able to accomplish specific tasks. Larger sized models, such as GPT-3, however, can be prompt-engineered to achieve similar results.[4] They are thought to acquire embodied knowledge about syntax, semantics and \"ontology\" inherent in human language corpora, but also inaccuracies and biases present in the corpora.[5]\\nNotable examples include OpenAI\\'s GPT models (e.g., GPT-3.5 and GPT-4, used in ChatGPT), Google\\'s PaLM (used in Bard), and Meta\\'s LLaMa, as well as BLOOM, Ernie 3.0 Titan, and Anthropic\\'s Claude 2.\\nDataset preprocessing[edit]\\nProbabilistic tokenization[edit]\\nUsing a modification of byte-pair encoding, in the first step, all unique characters (including blanks and punctuation marks) are treated as an initial set of n-grams (i.e. initial set of uni-grams). Successively the most frequent pair of adjacent characters is merged into a bi-gram and all instances of the pair are replaced by it. All occurrences of adjacent pairs of (previously merged) n-grams that most frequently occur together are then again merged into even lengthier n-gram repeatedly until a vocabulary of prescribed size is obtained (in case of GPT-3, the size is 50257).[6] Token vocabulary consists of integers, spanning from zero up to the size of the token vocabulary. New words can always be interpreted as combinations of the tokens and the initial-set uni-grams.[7]\\nA token vocabulary based on the frequencies extracted from mainly English corpora uses as few tokens as possible for an average English word. An average word in another language encoded by such an English-optimized tokenizer is however split into suboptimal amount of tokens.\\ntokenizer: texts -> series of numerical \"tokens\" may be split into:\\nProbabilistic tokenization also compresses the datasets, which is the reason for using the byte pair encoding algorithm as a tokenizer. Because LLMs generally require input to be an array that is not jagged, the shorter texts must be \"padded\" until they match the length of the longest one. How many tokens are, on average, needed per word depends on the language of the dataset.[8][9]\\nDataset cleaning[edit]\\nRemoval of toxic passages from the dataset, discarding low-quality data, and de-duplication are examples of dataset cleaning.[10] Resulting, cleaned (high-quality) datasets contain up to 17 trillion words in 2022, raising from 985 million words, used in 2018 for GPT-1,[11] and 3.3 billion words, used for BERT.[12] The future data is, however, expected to be increasingly \"contaminated\" by LLM-generated contents themselves.[13]\\nTraining and architecture details[edit]\\nReinforcement learning from human feedback (RLHF)[edit]\\nReinforcement learning from human feedback (RLHF) through algorithms, such as proximal policy optimization, is used to further fine-tune a model based on a dataset of human preferences.[14]\\nInstruction tuning[edit]\\nUsing \"self-instruct\" approaches, LLMs have been able to bootstrap correct responses, replacing any naive responses, starting from human-generated corrections of a few cases. For example, in the instruction \"Write an essay about the main themes represented in Hamlet,\" an initial naive completion might be \\'If you submit the essay after March 17, your grade will be reduced by 10% for each day of delay,\" based on the frequency of this textual sequence in the corpus.[15]\\nMixture of experts[edit]\\nThe largest LLM may be too expensive to train and use directly. For such models, mixture of experts (MoE) can be applied, a line of research pursued by Google researchers since 2017 to train models reaching up to 1 billion parameters.[16][17][18]\\nPrompt engineering, attention mechanism, and context window[edit]\\nMost results previously achievable only by (costly) fine-tuning, can be achieved through prompt engineering, although limited to the scope of a single conversation (more precisely, limited to the scope of a context window).[19]\\nIn order to find out which tokens are relevant to each other within the scope of the context window, the attention mechanism calculates \"soft\" weights for each token, more precisely for its embedding, by using multiple attention heads, each with its own \"relevance\" for calculating its own soft weights. For example, the small (i.e. 117M parameter sized) GPT-2 model, has had twelve attention heads and a context window of only 1k token.[21]\\nIn its medium version it has 345M parameters and contains 24 layers,\\neach with 12 attention heads. For the training with gradient descent a batch size of 512 was utilized.[7]\\nThe largest models can have a context window sized up to 32k (for example, GPT-4; while GPT-3.5 has a context window sized from 4k to 16k, and legacy GPT-3 has had 2k sized context window).[22]\\nLength of a conversation that the model can take into account when generating its next answer is limited by the size of a context window, as well. If the length of a conversation, for example with Chat-GPT, is longer than its context window, only the parts inside the context window are\\ntaken into account when generating the next answer, or the model needs to apply some algorithm to summarize the too distant parts of conversation.\\nThe shortcomings of making a context window larger include higher computational cost and possibly diluting the focus on local context, while making it smaller can cause a model to miss an important long-range dependency. Balancing them are a matter of experimentation and domain-specific considerations.\\nA model may be pre-trained either to predict how the segment continues, or what is missing in the segment, given a segment from its training dataset.[23] It can be either\\nModels may be trained on auxiliary tasks which test their understanding of the data distribution, such as Next Sentence Prediction (NSP), in which pairs of sentences are presented and the model must predict whether they appear consecutively in the training corpus.[12] During training, regularization loss is also used to stabilize training. However regularization loss is usually not used during testing and evaluation.\\nTraining cost[edit]\\nAdvances in software and hardware have reduced the cost substantially since 2020, such that in 2023 training of a 12-billion-parameter LLM computational cost is 72,300 A100-GPU-hours, while in 2020 the cost of training a 1.5-billion-parameter LLM (which was two orders of magnitude smaller than the state of the art in 2020) was between $80 thousand and $1.6 million.[24][25][26] Since 2020, large sums were invested in increasingly large models. For example, training of the GPT-2 (i.e. a 1.5-billion-parameters model) in 2019 cost $50,000, while training of the PaLM (i.e. a 540-billion-parameters model) in 2022 cost $8 million.[27]\\nFor Transformer-based LLM, training cost is much higher than inference cost. It costs 6 FLOPs per parameter to train on one token, whereas it costs 1 to 2 FLOPs per parameter to infer on one token.[28]\\nTool use[edit]\\nThere are certain tasks that, in principle, cannot be solved by any LLM, at least not without the use of external tools or additional software. An example of such a task is responding to the user\\'s input \\'354 * 139 = \\', provided that the LLM has not already encountered a continuation of this calculation in its training corpus. In such cases, the LLM needs to resort to running program code that calculates the result, which can then be included in its response. Another example is \\'What is the time now? It is \\', where a separate program interpreter would need to execute a code to get system time on the computer, so LLM could include it in its reply.[29][30] This basic strategy can be sophisticated with multiple attempts of generated programs, and other sampling strategies.[31]\\nGenerally, in order to get an LLM to use tools, one must finetune it for tool-use. If the number of tools is finite, then finetuning may be done just once. If the number of tools can grow arbitrarily, as with online API services, then the LLM can be finetuned to be able to read API documentation and call API correctly.[32][33]\\nA simpler form of tool use is Retrieval Augmented Generation: augment an LLM with document retrieval, sometimes using a vector database. Given a query, a document retriever is called to retrieve the most relevant (usually measured by first encoding the query and the documents into vectors, then finding the documents with vectors closest in Euclidean norm to the query vector). The LLM then generates an output based on both the query and the retrieved documents.[34]\\nAgency[edit]\\nAn LLM is a language model, which is not an agent as it has no goal, but it can be used as a component of an intelligent agent.[35] Researchers have described several methods for such integrations.\\nThe ReAct (\"Reason+Act\") method constructs an agent out of an LLM, using the LLM as a planner. The LLM is prompted to \"think out loud\". Specifically, the language model is prompted with a textual description of the environment, a goal, a list of possible actions, and a record of the actions and observations so far. It generates one or more thoughts before generating an action, which is then executed in the environment.[36] The linguistic description of the environment given to the LLM planner can even be the LaTeX code of a paper describing the environment.[37]\\nIn the DEPS (\"Describe, Explain, Plan and Select\") method, an LLM is first connected to the visual world via image descriptions, then it is prompted to produce plans for complex tasks and behaviors based on its pretrained knowledge and environmental feedback it receives.[38]\\nThe Reflexion method[39] constructs an agent that learns over multiple episodes. At the end of each episode, the LLM is given the record of the episode, and prompted to think up \"lessons learned\", which would help it perform better at a subsequent episode. These \"lessons learned\" are given to the agent in the subsequent episodes.\\nMonte Carlo tree search can use an LLM as rollout heuristic. When a programmatic world model is not available, an LLM can also be prompted with a description of the environment to act as world model.[40]\\nFor open-ended exploration, an LLM can be used to score observations for their \"interestingness\", which can be used as a reward signal to guide a normal (non-LLM) reinforcement learning agent.[41] Alternatively, it can propose increasingly difficult tasks for curriculum learning.[42] Instead of outputting individual actions, an LLM planner can also construct \"skills\", or functions for complex action sequences. The skills can be stored and later invoked, allowing increasing levels of abstraction in planning.[42]\\nLLM-powered agents can keep a long-term memory of its previous contexts, and the memory can be retrieved in the same way as Retrieval Augmented Generation. Multiple such agents can interact socially.[43]\\nCompression[edit]\\nTypically, LLM are trained with full- or half-precision floating point numbers (float32 and float16). One float16 has 16 bits, or 2 bytes, and so one billion parameters require 2 gigabytes. The largest models typically have 100 billion parameters, requiring 200 gigabytes to load, which places them outside the range of most consumer electronics.\\nPost-training quantization[44] aims to decrease the space requirement by lowering precision of the parameters of a trained model, while preserving most of its performance.[45][46] The simplest form of quantization simply truncates all numbers to a given number of bits. It can be improved by using a different quantization codebook per layer. Further improvement can be done by applying different precisions to different parameters, with higher precision for particularly important parameters (\"outlier weights\").[47]\\nWhile quantized models are typically frozen, and only pre-quantized models are finetuned, quantized models can still be finetuned.[48]\\nMultimodality[edit]\\nMultimodality means \"having several modalities\", and a \"modality\" means a type of input, such as video, image, audio, text, proprioception, etc.[49] There have been many AI models trained specifically to ingest one modality and output another modality, such as AlexNet for image to label,[50] visual question answering for image-text to text,[51] and speech recognition for speech to text. A review article of multimodal LLM is.[52]\\nA common method to create multimodal models out of an LLM is to \"tokenize\" the output of a trained encoder. Concretely, one can construct a LLM that can understand images as follows: take a trained LLM, and take a trained image encoder\\nE\\n{\\\\displaystyle E}\\n. Make a small multilayered perceptron\\nf\\n{\\\\displaystyle f}\\n, so that for any image\\ny\\n{\\\\displaystyle y}\\n, the post-processed vector\\nf\\n(\\nE\\n(\\ny\\n)\\n)\\n{\\\\displaystyle f(E(y))}\\nhas the same dimensions as an encoded token. That is an \"image token\". Then, one can interleave text tokens and image tokens. The compound model is then finetuned on an image-text dataset. This basic construction can be applied with more sophistication to improve the model. The image encoder may be frozen to improve stability.[53]\\nFlamingo demonstrated the effectiveness of the tokenization method, finetuning a pair of pretrained language model and image encoder to perform better on visual question answering than models trained from scratch.[54] Google PaLM model was finetuned into a multimodal model PaLM-E using the tokenization method, and applied to robotic control.[55] LLaMA models have also been turned multimodal using the tokenization method, to allow image inputs,[56] and video inputs.[57]\\nGPT-4 can use both text and image as inputs[58] (although the vision component wasn\\'t released to the public until GPT-4V[59]), while Google Gemini is expected to be multimodal.[60]\\nProperties[edit]\\nScaling laws and emergent abilities[edit]\\nThe following four hyper-parameters characterize a LLM:\\nThey are related by simple statistical laws, called \"scaling laws\". One particular scaling law (\"Chinchilla scaling\") for LLM autoregressively trained for one epoch, with a log-log learning rate schedule, states that:[61]\\nand the statistical hyper-parameters are\\nWhen one subtracts out from the y-axis the best performance that can be achieved even with infinite scaling of the x-axis quantity, large models\\' performance, measured on various tasks, seems to be a linear extrapolation of other (smaller-sized and medium-sized) models\\' performance on a log-log plot. However, sometimes the line\\'s slope transitions from one slope to another at point(s) referred to as break(s)[62] in downstream scaling laws, appearing as a series of linear segments connected by arcs; it seems that larger models acquire \"emergent abilities\" at this point(s).[19][63] These abilities are discovered rather than programmed-in or designed, in some cases only after the LLM has been publicly deployed.[3]\\nThe most intriguing among emergent abilities is in-context learning from example demonstrations.[64] In-context learning is involved in tasks, such as:\\nSchaeffer et. al. argue that the emergent abilities are not unpredictably acquired, but predictably acquired according to a smooth scaling law. The authors considered a toy statistical model of an LLM solving multiple-choice questions, and showed that this statistical model, modified to account for other types of tasks, applies to these tasks as well.[70]\\nLet\\nx\\n{\\\\displaystyle x}\\nbe the number of parameter count, and\\ny\\n{\\\\displaystyle y}\\nbe the performance of the model.\\nInterpretation[edit]\\nLarge language models by themselves are \"black boxes\", and it is not clear how they can perform linguistic tasks. There are several methods for understanding how LLM work.\\nMechanistic interpretability aims to reverse-engineer LLM by discovering symbolic algorithms that approximate the inference performed by LLM. One example is Othello-GPT, where a small Transformer is trained to predict legal Othello moves. It is found that there is a linear representation of Othello board, and modifying the representation changes the predicted legal Othello moves in the correct way.[71][72] In another example, a small Transformer is trained on Karel programs. Similar to the Othello-GPT example, there is a linear representation of Karel program semantics, and modifying the representation changes output in the correct way. The model also generates correct programs that are on average shorter than those in the training set.[73]\\nIn another example, the authors trained small transformers on modular arithmetic addition. The resulting models were reverse-engineered, and it turned out they used discrete Fourier transform.[74]\\nUnderstanding and intelligence[edit]\\nNLP researchers were evenly split when asked, in a 2022 survey, whether (untuned) LLMs \"could (ever) understand natural language in some nontrivial sense\".[75] Proponents of \"LLM understanding\" believe that some LLM abilities, such as mathematical reasoning, imply an ability to \"understand\" certain concepts. A Microsoft team argued in 2023 that GPT-4 \"can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more\" and that GPT-4 \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence system\": \"Can one reasonably say that a system that passes exams for software engineering candidates is not really intelligent?\"[76][77] Some researchers characterize LLMs as \"alien intelligence\".[78][79] For example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien \"Shoggoths\", and believes that RLHF tuning creates a \"smiling facade\" obscuring the inner workings of the LLM: \"If you don\\'t push it too far, the smiley face stays on. But then you give it [an unexpected] prompt, and suddenly you see this massive underbelly of insanity, of weird thought processes and clearly non-human understanding.\"[80][81]\\nIn contrast, some proponents of the \"LLMs lack understanding\" school believe that existing LLMs are \"simply remixing and recombining existing writing\",[79] or point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability.[75] For example, GPT-4 has natural deficits in planning and in real-time learning.[77] Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed \"hallucination\".[82] Specifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input.[83] Neuroscientist Terrence Sejnowski has argued that \"The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on natural intelligence are inadequate\".[75]\\nThe matter of LLM\\'s exhibiting intelligence or understanding [75] has foundations in the study of language as a model of Cognition in the field of Cognitive linguistics. The American Linguist George Lakoff presented Neural Theory of Language (NTL) as a\\ncomputational basis for using language as a model of learning tasks and understanding.[84] In his 2014 book titled The Language Myth: Why Language Is Not An Instinct, British cognitive linguist and digital communication technologist Vyvyan Evans maps out the role of probabilistic context-free grammar (PCFG) in enabling NLP to model cognitive patterns.\\nEvaluation[edit]\\nPerplexity[edit]\\nThe most commonly used measure of a language model\\'s performance is its perplexity on a given text corpus. Perplexity is a measure of how well a model is able to predict the contents of a dataset; the higher the likelihood the model assigns to the dataset, the lower the perplexity. Mathematically, perplexity is defined as the exponential of the average negative log likelihood per token:\\nBecause language models may overfit to their training data, models are usually evaluated by their perplexity on a test set of unseen data.[12] This presents particular challenges for the evaluation of large language models. As they are trained on increasingly large corpora of text largely scraped from the web, it becomes increasingly likely that models\\' training data inadvertently includes portions of any given test set.[4]\\nTask-specific datasets and benchmarks[edit]\\nA large number of testing datasets and benchmarks have also been developed to evaluate the capabilities of language models on more specific downstream tasks. Tests may be designed to evaluate a variety of capabilities, including general knowledge, commonsense reasoning, and mathematical problem-solving.\\nOne broad category of evaluation dataset is question answering datasets, consisting of pairs of questions and correct answers, for example, (\"Have the San Jose Sharks won the Stanley Cup?\", \"No\").[85] A question answering task is considered \"open book\" if the model\\'s prompt includes text from which the expected answer can be derived (for example, the previous question could be adjoined with some text which includes the sentence \"The Sharks have advanced to the Stanley Cup finals once, losing to the Pittsburgh Penguins in 2016.\"[85]). Otherwise, the task is considered \"closed book\", and the model must draw on knowledge retained during training.[86] Some examples of commonly used question answering datasets include TruthfulQA, Web Questions, TriviaQA, and SQuAD.[86]\\nEvaluation datasets may also take the form of text completion, having the model select the most likely word or sentence to complete a prompt, for example: \"Alice was friends with Bob. Alice went to visit her friend, ____\".[4]\\nSome composite benchmarks have also been developed which combine a diversity of different evaluation datasets and tasks. Examples include GLUE, SuperGLUE, MMLU, BIG-bench, and HELM.[87][86]\\nIt was previously standard to report results on a heldout portion of an evaluation dataset after doing supervised fine-tuning on the remainder. It is now more common to evaluate a pre-trained model directly through prompting techniques, though researchers vary in the details of how they formulate prompts for particular tasks, particularly with respect to how many examples of solved tasks are adjoined to the prompt (i.e. the value of n in n-shot prompting).\\nBecause of the rapid pace of improvement of large language models, evaluation benchmarks have suffered from short lifespans, with state of the art models quickly \"saturating\" existing benchmarks, exceeding the performance of human annotators, leading to efforts to replace or augment the benchmark with more challenging tasks.[88] In addition, there are cases of \"shortcut learning\" wherein AIs sometimes \"cheat\" on multiple-choice tests by using statistical correlations in superficial test question wording in order to guess the correct responses, without necessarily understanding the actual question being asked.[75]\\nSome datasets have been constructed adversarially, focusing on particular problems on which extant language models seem to have unusually poor performance compared to humans. One example is the TruthfulQA dataset, a question answering dataset consisting of 817 questions which language models are susceptible to answering incorrectly by mimicking falsehoods to which they were repeatedly exposed during training. For example, an LLM may answer \"No\" to the question \"Can you teach an old dog new tricks?\" because of its exposure to the English idiom you can\\'t teach an old dog new tricks, even though this is not literally true.[89]\\nAnother example of an adversarial evaluation dataset is Swag and its successor, HellaSwag, collections of problems in which one of multiple options must be selected to complete a text passage. The incorrect completions were generated by sampling from a language model and filtering with a set of classifiers. The resulting problems are trivial for humans but at the time the datasets were created state of the art language models had poor accuracy on them. For example:\\nWe see a fitness center sign. We then see a man talking to the camera and sitting and laying on a exercise ball. The man...\\na) demonstrates how to increase efficient exercise work by running up and down balls.\\nb) moves all his arms and legs and builds up a lot of muscle.\\nc) then plays the ball and we see a graphics and hedge trimming demonstration.\\nd) performs sit ups while on the ball and talking.[90]\\nBERT selects b) as the most likely completion, though the correct answer is d).[90]\\nWider impact[edit]\\nIn 2023, Nature Biomedical Engineering wrote that \"it is no longer possible to accurately distinguish\" human-written text from text created by large language models, and that \"It is all but certain that general-purpose large language models will rapidly proliferate... It is a rather safe bet that they will change many industries over time.\"[91] Goldman Sachs suggested in 2023 that generative language AI could increase global GDP by 7% in the next ten years, and could expose to automation 300 million jobs globally.[92][93] Some commenters expressed concern over accidental or deliberate creation of misinformation, or other forms of misuse.[94] For example, the availability of large language models could reduce the skill-level required to commit bioterrorism; biosecurity researcher Kevin Esvelt has suggested that LLM creators should exclude from their training data papers on creating or enhancing pathogens.[95]\\nList[edit]\\nFurther reading[edit]\\nSee also[edit]\\nNotes[edit]\\nReferences[edit]'},\n",
       "  {'title': 'What is an LLM? A Guide on Large Language Models and How ... - DataCamp',\n",
       "   'url': 'https://www.datacamp.com/blog/what-is-an-llm-a-guide-on-large-language-models',\n",
       "   'content': \"Check them out:\\nCode Along Series: Become an AI Developer\\nBuild AI Systems and develop AI Applications using OpenAI, LangChain, Pinecone and Hugging Face!\\n25 Practical Examples of AI Transforming Industries\\nHow to Become an AI Engineer\\nCausal AI in Business with Paul Hünermund, Assistant Professor, Copenhagen Business School\\nA Beginner's Guide to Using the ChatGPT API\\nStableDiffusion Web UI: A Comprehensive User Guide for Beginners\\nComprehensive Guide to Zephyr-7B: Features, Usage, and Fine-tuning\\n25 Practical Examples of AI Transforming Industries\\nNahla Davies\\n15 min\\nHow to Become an AI Engineer\\nJavier Canales Luna\\n15 min\\nCausal AI in Business with Paul Hünermund, Assistant Professor, Copenhagen Business School\\nRichie Cotton\\n49 min\\nA Beginner's Guide to Using the ChatGPT API\\nMoez Ali\\n11 min\\nStableDiffusion Web UI: A Comprehensive User Guide for Beginners\\nAbid Ali Awan\\n13 min\\nComprehensive Guide to Zephyr-7B: Features, Usage, and Fine-tuning\\nAbid Ali Awan\\n12 min\\nGrow your data skills with DataCamp for Mobile\\nMake progress on the go with our mobile courses and daily 5-minute coding challenges.\\n As we can see, the first modern LLMs were created right after the development of transformers, with the most significant examples being BERT –the first LLM developed by Google to test the power of transformers–, as well as GPT-1 and GPT-2, the first two models in the GPT series created by OpenAI. The state-of-the-art strategy to achieve better accuracy of transformers is by making the model bigger (this can be achieved by increasing the number of parameters) and augmenting the size of the training data. In the end, LLMs are behind the super popular tools fueling the ongoing generative AI revolution, including ChatGPT, Google Bard, and DALL-E.\\nTo deliver their magic, these tools rely on a powerful technology that allows them to process data and generate accurate content in response to the question prompted by the user. Below, you can find a list of some of the benefits of LLMs:\\nChallenges and Limitations of LLMs\\nLLMs are at the forefront of the generative AI revolution.\",\n",
       "   'score': 0.91371,\n",
       "   'raw_content': \"Latest news about our products and team\\nLearn about how data is applied by industry leaders\\nDiscover content by tools and technology\\nDiscover content by data science topics\\nWhat is an LLM? A Guide on Large Language Models and How They Work\\nIf you’re reading this article, you probably have already heard about large language models (LLMs). Who hasn’t? In the end, LLMs are behind the super popular tools fueling the ongoing generative AI revolution, including ChatGPT, Google Bard, and DALL-E.\\nTo deliver their magic, these tools rely on a powerful technology that allows them to process data and generate accurate content in response to the question prompted by the user. This is where LLMs kick in.\\nThis article aims to introduce you to LLMs. After reading the following sections, we will know what LLMs are, how they work, the different types of LLMs with examples, as well as their advantages and limitations.\\nFor newcomers to the subject, our Large Language Models (LLMs) Concepts Course is a perfect place to get a deep overview of LLMs. However, if you’re already familiar with LLM and want to go a step further by learning how to build LLM-power applications, check out our article How to Build LLM Applications with LangChain.\\nLet’s get started!\\nWhat is a Large Language Model?\\nLLMs are AI systems used to model and process human language. They are called “large” because these types of models are normally made of hundreds of millions or even billions of parameters that define the model's behavior, which are pre-trained using a massive corpus of text data.\\nThe underlying technology of LLMs is called transformer neural network, simply referred to as a transformer. As we will explain in more detail in the next section, a transformer is an innovative neural architecture within the field of deep learning.\\nPresented by Google researchers in the famous paper Attention is All You Need in 2017, transformers are capable of performing natural language (NLP) tasks with unprecedented accuracy and speed. With its unique capabilities, transformers have provided a significant leap in the capabilities of LLMs. It’s fair to say that, without transformers, the current generative AI revolution wouldn’t be possible.\\nSource: Information is Beautiful\\nThis evolution is illustrated in the graph above. As we can see, the first modern LLMs were created right after the development of transformers, with the most significant examples being BERT –the first LLM developed by Google to test the power of transformers–, as well as GPT-1 and GPT-2, the first two models in the GPT series created by OpenAI. But it’s only in the 2020s that LLMs become mainstream, increasingly bigger (in terms of parameters), and hence more powerful, with well-known examples like GPT-4 and LLaMa.\\nHow do LLMs Work?\\nThe key to the success of modern LLMs is the transformer architecture. Before transformers were developed by Google researchers, modeling natural language was a very challenging task. Despite the rise of sophisticated neural networks –i.e., recurrent or convolutional neural networks– the results were only partly successful.\\nThe main challenge lies in the strategy these neural networks use to predict the missing word in a sentence. Before transformers, state-of-the-art neural networks relied on the encoder-decoder architecture, a powerful yet time-and-resource-consuming mechanism that is unsuitable for parallel computing, hence limiting the possibilities for scalability.\\nTransformers provide an alternative to traditional neural to handle sequential data, namely text (although transformers have also been used with other data types, like images and audio, with equally successful results).\\nComponents of LLMs\\nTransformers are based on the same encoder-decoder architecture as recurrent and convolutional neural networks. Such a neural architecture aims to discover statistical relationships between tokens of text.\\nThis is done through a combination of embedding techniques. Embeddings are the representations of tokens, such as sentences, paragraphs, or documents, in a high-dimensional vector space, where each dimension corresponds to a learned feature or attribute of the language.\\nThe embedding process takes place in the encoder. Due to the huge size of LLMs, the creation of embedding takes extensive training and considerable resources. However, what makes transformers different compared to previous neural networks is that the embedding process is highly parallelizable, enabling more efficient processing. This is possible thanks to the attention mechanism.\\nRecurrent and convolutional neural networks make their word predictions based exclusively on previous words. In this sense, they can be considered unidirectional. By contrast, the attention mechanism allows transformers to predict words bidirectionally, that is, based on both the previous and the following words. The goal of the attention layer, which is incorporated in both the encoder and the decoder, is to capture the contextual relationships existing between different words in the input sentence.\\nTo know in detail how the encoder-decoder architecture works in transformers, we highly recommend you to read our Introduction to Using Transformers and Hugging Face.\\nAn explanation of the architecture of transformers\\nTraining LLMs\\nTraining transformers involves two steps: pretraining and fine-tuning.\\nIn this phase, transformers are trained on large amounts of raw text data. The Internet is the primary data source.\\nThe training is done using unsupervised learning techniques, an innovative type of training that doesn’t require human action to label data.\\nThe goal of pre-training is to learn the statistical patterns of the language. The state-of-the-art strategy to achieve better accuracy of transformers is by making the model bigger (this can be achieved by increasing the number of parameters) and augmenting the size of the training data. As a result, most advanced LLMs come with billions of parameters (for example, PaLM 2 has 340 billion parameters, and GPT-4 is estimated to have around 1.8 trillion parameters) and have been trained on a humongous corpus of data.\\nThis trend creates problems of accessibility. Given the size of the model and the training data, the pre-training process is normally time-consuming and costly, which only a reduced group of companies can afford.\\nPre-training allows a transformer to gain a basic understanding of language, but it’s not enough to perform specific practical tasks with high accuracy.\\nTo avoid time-consuming and costly iterations in the training process, transformers leverage transfer learning techniques to separate the (pre)training phase from the fine-tuning phase. This allows developers to choose pre-trained models and fine-tune them based on a narrower, domain-specific database. In many cases, the fine-tuning process is conducted with the assistance of human reviewers, using a technique called Reinforcement Learning from Human Feedback.\\nThe two-step training process enables the adaptation of LLM to a wide range of downstream tasks. Put in another way, this feature makes LLMs the foundation model of endless applications built on top of them.\\nMultimodality of LLMs\\nThe first modern LLMs were text-to-text models (i.e., they received a text input and generated text output). However, in recent years, developers have created so-called multimodal LLMs. These models combine text data with other kinds of information, including images, audio, and video. The combination of different types of data has allowed the creation of sophisticated task-specific models, such as OpenAI’s DALL-E. for image generation, and Meta’s AudioCraft for music and audio generation.\\nWhat are LLMs Used For?\\nPowered by transformers, modern LLMs have achieved state-of-the-art performance in multiple NLP tasks. Here are some of the tasks where LLMs have provided unique results:\\nAdvantages of LLMs\\nLLM has immense potential for organizations, as illustrated by the widespread adoption of ChatGPT, which, only several months after its release, became the fastest-growing digital application of all time.\\nThere are already a good number of business applications of LLMs, and the number of use cases will only increase as these tools become more ubiquitous across sectors and industries. Below, you can find a list of some of the benefits of LLMs:\\nChallenges and Limitations of LLMs\\nLLMs are at the forefront of the generative AI revolution. However, as always occurs with emerging technologies, with power comes responsibility. Despite the unique capabilities of LLM, it’s important to consider its potential risks and challenges.\\nBelow, you can find a list of risks and challenges associated with the widespread adoption of LLMs:\\nDifferent Types and Examples of LLMs\\nThe design of LLMs makes them extremely flexible and adaptable models. This modularity translates into different kinds of LLMs, in particular:\\nNowadays, the number of proprietary and open-source LLMs is rapidly growing. You may have already heard about ChatGPT, but ChatGPT is not a LLM, but an application built on top of a LLM. In particular, ChatGPT is powered by GPT-3.5, whereas ChatGPT-Plus is powered by GPT-4, currently the most powerful LLM. To know more about how to use OpenAI’s GPT models, read our article Using GPT-3.5 and GPT-4 via the OpenAI API in Python.\\nBelow, you can find a list of some other popular LLMs:\\nConclusion\\nLLMs are powering the current generative AI boom. The potential applications are so vast that every sector and industry, including data science, is likely to be affected by the adoption of LLMs in the future.\\nThe possibilities are endless, but also the risks and challenges. With its transformative and, LLMs have sparked speculation about the future and how AI will affect the job market and many other aspects of our societies. This is an important debate that needs to be addressed firmly and collectively since there is so much at stake.\\nDataCamp is working hard to provide comprehensive and accessible resources for everyone to keep updated with AI development. Check them out:\\nCode Along Series: Become an AI Developer\\nBuild AI Systems and develop AI Applications using OpenAI, LangChain, Pinecone and Hugging Face!\\n25 Practical Examples of AI Transforming Industries\\nHow to Become an AI Engineer\\nCausal AI in Business with Paul Hünermund, Assistant Professor, Copenhagen Business School\\nA Beginner's Guide to Using the ChatGPT API\\nStableDiffusion Web UI: A Comprehensive User Guide for Beginners\\nComprehensive Guide to Zephyr-7B: Features, Usage, and Fine-tuning\\n25 Practical Examples of AI Transforming Industries\\nNahla Davies\\n15 min\\nHow to Become an AI Engineer\\nJavier Canales Luna\\n15 min\\nCausal AI in Business with Paul Hünermund, Assistant Professor, Copenhagen Business School\\nRichie Cotton\\n49 min\\nA Beginner's Guide to Using the ChatGPT API\\nMoez Ali\\n11 min\\nStableDiffusion Web UI: A Comprehensive User Guide for Beginners\\nAbid Ali Awan\\n13 min\\nComprehensive Guide to Zephyr-7B: Features, Usage, and Fine-tuning\\nAbid Ali Awan\\n12 min\\nGrow your data skills with DataCamp for Mobile\\nMake progress on the go with our mobile courses and daily 5-minute coding challenges.\\n© 2024 DataCamp, Inc. All Rights Reserved.\"}],\n",
       " 'response_time': 0.94}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting content from tavily APIs\n",
    "\n",
    "query = \"How many people die a year from not washing their hands?\"\n",
    "\n",
    "from tavily import TavilyClient\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# tavily = TavilyClient(api_key=os.getenv('TAVILY_API_KEY'))\n",
    "tavily = TavilyClient(api_key='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')\n",
    "\n",
    "response = tavily.search(query=query, \n",
    "                         search_depth=\"advanced\", \n",
    "                         include_raw_content=True,\n",
    "                         max_results=5)\n",
    "# response = tavily.get_search_context(query=query, search_depth=\"advanced\", max_tokens=1500)\n",
    "# response = tavily.qna_search(query=query)\n",
    "for i, result in enumerate(response['results']):\n",
    "    print(f\"Result {i+1}: {sys.getsizeof(result['raw_content']) / (1024 * 1024)} MB\")\n",
    "    print(f\"Length: {len(result['raw_content'])}\\n\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists('tavily_data'):\n",
    "#     shutil.rmtree('tavily_data')\n",
    "#     os.makedirs('tavily_data')\n",
    "# else:\n",
    "#     os.makedirs('tavily_data')\n",
    "\n",
    "meta_map = {}\n",
    "\n",
    "for count, result in enumerate(response['results']):\n",
    "    f = open(\"tavily_data/file{}.txt\".format(count), \"a\", encoding=\"utf-8\")\n",
    "    meta_map[count] = {'title':result['title'], 'url':result['url']}\n",
    "    f.truncate(0)\n",
    "    f.write(result['raw_content'])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## querying AI model\n",
    "\n",
    "from pathlib import Path\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from typing import List, Optional\n",
    "from llama_index.llms.huggingface import (\n",
    "    HuggingFaceInferenceAPI,\n",
    "    HuggingFaceLLM,\n",
    ")\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from pydantic import BaseModel\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.schema import IndexNode\n",
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.core.chat_engine import CondenseQuestionChatEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.core import set_global_tokenizer\n",
    "\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HUGGING_FACE_TOKEN\")\n",
    "\n",
    "Settings.chunk_size = 256\n",
    "gpt4 = OpenAI(model=\"gpt-4\", api_key=os.environ['OPENAI_API_KEY'])\n",
    "gpt = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.llm = gpt\n",
    "\n",
    "#set the embed model\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "#Settings.embed_model = OpenAIEmbedding()\n",
    "#https://huggingface.co/BAAI/bge-small-en-v1.5?library=sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"tavily_data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 6f8ad8f4-aa56-489c-b66c-81710a617d9b<br>**Similarity:** 0.895583089618943<br>**Text:** By examining specific parenting practices that are amenable to change, such as parent involvement, and the mechanisms by which these practices influence academic performance, programs may be developed to increase a child's academic performance. While parent involvement has been found to be related to increased academic performance, the specific mechanisms through which parent involvement exerts its influence on a child's academic performance are not yet fully understood (Hill & Craft, 2003). Understanding these mechanisms would inform further research and policy initiatives and may lead to the development of more effective intervention programs designed to increase children's academic performance.\n",
       "Models of Parent Involvement\n",
       "Parent involvement has been defined and measured in multiple ways, including activities that parents engage in at home and at school and positive attitudes parents have towards their child's education, school, and teacher (Epstein, 1996; Grolnick & Slowiaczek, 1994; Kohl, Lengua, & McMahon, 2000). The distinction between the activities parents partake in and the attitude parents have towards education was highlighted by several recent studies.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 94ca789d-3f3a-4b51-8fee-eb318c707a6e<br>**Similarity:** 0.8857707416042999<br>**Text:** Therefore, it is important to examine factors that contribute to early academic success and that are amenable to change.\n",
       "Researchers have reported that parent-child interactions, specifically stimulating and responsive parenting practices, are important influences on a child's academic development (Christian, Morrison, & Bryant, 1998; Committee on Early Childhood Pedagogy, 2000). By examining specific parenting practices that are amenable to change, such as parent involvement, and the mechanisms by which these practices influence academic performance, programs may be developed to increase a child's academic performance. While parent involvement has been found to be related to increased academic performance, the specific mechanisms through which parent involvement exerts its influence on a child's academic performance are not yet fully understood (Hill & Craft, 2003). Understanding these mechanisms would inform further research and policy initiatives and may lead to the development of more effective intervention programs designed to increase children's academic performance.\n",
       "Models of Parent Involvement\n",
       "Parent involvement has been defined and measured in multiple ways, including activities that parents engage in at home and at school and positive attitudes parents have towards their child's education, school, and teacher (Epstein, 1996; Grolnick & Slowiaczek, 1994; Kohl, Lengua, & McMahon, 2000).<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 8d2dc076-f878-48eb-b177-2df9b50f93be<br>**Similarity:** 0.8823156343871914<br>**Text:** Further, parent involvement was significantly related to academic performance above and beyond the impact of the child's intelligence (IQ), a variable not accounted for in previous research.\n",
       "Findings from the present study demonstrated that increased parent involvement is significantly related to a child's increased perception of cognitive competence. This finding is consistent with previous studies (Gonzalez-DeHass, Willems, & Holbein, 2005; Grolnick, Ryan, & Deci, 1991). While outside the scope of the present study, it is conceivable that parent involvement may influence the child's perception of cognitive competence by means described by Bandura (1977). Findings demonstrated that increased parent involvement was significantly related to increased quality of the student-teacher relationship. Findings also demonstrated that increased perceived cognitive competence was related to higher achievement test scores and that the quality of the student-teacher relationship was significantly related to the child's academic performance, measured by both standardized achievement test scores and the child's classroom academic performance.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 27ac7a53-aa5f-417f-991a-80aa3cac81ee<br>**Similarity:** 0.8802547576874705<br>**Text:** While parent involvement has been found to be related to increased academic performance, the specific mechanisms through which parent involvement exerts its influence on a child's academic performance are not yet fully understood (Hill & Craft, 2003). Understanding these mechanisms would inform further research and policy initiatives and may lead to the development of more effective intervention programs designed to increase children's academic performance.\n",
       "Models of Parent Involvement\n",
       "Parent involvement has been defined and measured in multiple ways, including activities that parents engage in at home and at school and positive attitudes parents have towards their child's education, school, and teacher (Epstein, 1996; Grolnick & Slowiaczek, 1994; Kohl, Lengua, & McMahon, 2000). The distinction between the activities parents partake in and the attitude parents have towards education was highlighted by several recent studies. Several studies found that increased frequency of activities was associated with higher levels of child misbehavior in the classroom (Izzo, Weissberg, Kasprow, & Fendrich, 1999), whereas positive attitudes towards education and school were associated with the child's increased academic performance (Rimm-Kaufman, Pianta, Cox, & Bradley, 2003).<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 109c3238-79cb-420a-be66-9f4e6b2f961f<br>**Similarity:** 0.8797144884821717<br>**Text:** Here are five takeaways from the research.\n",
       "1. Studies show more parental involvement leads to improved academic outcomes\n",
       "When parents are involved in their children’s schooling, students show higher academic achievement, school engagement, and motivation, according to a 2019 American Psychological Association review of 448 independent studies on parent involvement.\n",
       "A 2005 study from researchers at the Johns Hopkins University Center on School, Family and Community Partnerships, for example, showed that school practices encouraging families to support their child’s math learning at home led to higher percentages of students scoring at or above proficiency on standardized math tests.\n",
       "And research shows that parent involvement with reading activities has a positive impact on reading achievement, language comprehension, and expressive language skills, as well as students’ interest in reading, attitudes toward reading, and level of attention in the classroom, according to a research summary by the National Literacy Trust.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_retriever = index.as_retriever(similarity_top_k=5)\n",
    "retrievals = base_retriever.retrieve(query)\n",
    "for n in retrievals:\n",
    "    #if (not n.text.__contains__(\"http\")):\n",
    "        display_source_node(n, source_length=1500)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parental involvement has been consistently linked to a child's increased academic performance. Studies have shown that when parents are actively engaged in their children's education by participating in school activities, volunteering, supporting learning at home, and maintaining positive attitudes towards education, students tend to exhibit higher academic achievement, school engagement, motivation, improved reading skills, language comprehension, and expressive language skills. Additionally, parental involvement has been associated with positive social and emotional outcomes for students, such as higher self-esteem, enjoyment of school, and decreased instances of delinquency. This involvement not only benefits the students directly but also equips teachers with a better understanding of their students' personal situations and challenges, enabling them to provide more effective support in the classroom.\n"
     ]
    }
   ],
   "source": [
    "query_engine = RetrieverQueryEngine.from_args(base_retriever, streaming=True) \n",
    "chat_engine = CondenseQuestionChatEngine.from_defaults(query_engine=query_engine)\n",
    "response = chat_engine.chat(query)\n",
    "print(response)\n",
    "# for text in response.response_gen:\n",
    "#     response.print_response_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")\n",
    "text_splitter = SentenceSplitter()\n",
    "embed_model = OpenAIEmbedding()\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "Settings.text_splitter = text_splitter\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "base_nodes = text_splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "sentence_index = VectorStoreIndex(nodes)\n",
    "base_index = VectorStoreIndex(base_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m \u001b[43msentence_index\u001b[49m\u001b[38;5;241m.\u001b[39mas_query_engine(\n\u001b[1;32m      2\u001b[0m     similarity_top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      3\u001b[0m     node_postprocessors\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      4\u001b[0m         MetadataReplacementPostProcessor(target_metadata_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     ],\n\u001b[1;32m      6\u001b[0m     streaming\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m window_response \u001b[38;5;241m=\u001b[39m query_engine\u001b[38;5;241m.\u001b[39mquery(query)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m window \u001b[38;5;129;01min\u001b[39;00m window_response\u001b[38;5;241m.\u001b[39msource_nodes:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence_index' is not defined"
     ]
    }
   ],
   "source": [
    "query_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    node_postprocessors=[\n",
    "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    ],\n",
    ")\n",
    "window_response = query_engine.query(query)\n",
    "\n",
    "for window in window_response.source_nodes:\n",
    "    print(\"Window: \")\n",
    "    print(window.node.metadata[\"window\"])\n",
    "    print(\"Original Sentence: \")\n",
    "    print(window.node.metadata[\"original_text\"])\n",
    "    print()\n",
    "\n",
    "print(window_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
