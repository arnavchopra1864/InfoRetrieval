{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    "    PromptTemplate\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core.chat_engine import CondenseQuestionChatEngine\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from llama_index.readers.semanticscholar import SemanticScholarReader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x1c31540e0d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(BaseModel):\n",
    "    \"\"\"Data model for output. If answer is not in the data then say that and do not provide a supporting paragraph. Make your respose concise and informative.\"\"\"\n",
    "\n",
    "    answer: str\n",
    "    paragraphs_supporting_answer_directly_quoted_from_data: List[str]\n",
    "    #page_numbers_of_each_paragraph: List[int]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "query_engine = index.as_query_engine(\n",
    "    response_mode=\"refine\", \n",
    "    llm = llm,\n",
    "    output_cls=Output\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI can be utilized for personalization through personalized policies and methodological approaches, addressing scalability, generalizability, and counterfactual validity. Evaluation methods like the Direct method, Inverse Propensity Score estimator, and Doubly Robust method can be employed for static policies. AI's application extends to continuous actions and dynamic settings, enhancing personalization outcomes across domains such as content recommendation, advertising, and promotions. Furthermore, AI's role intersects with welfare concepts like search costs, privacy, fairness, and polarization within the realm of personalization.\n",
      "\n",
      "This paper reviews the recent developments at the intersection of personalization and AI in marketing and related fields. We provide a formal definition of personalized policy and review the methodological approaches available for personalization. We discuss scalability, generalizability, and counterfactual validity issues and briefly touch upon advanced methods for online/interactive/dynamic settings. We then summarize the three evaluation approaches for static policies \n",
      "â€“ the Direct method, the Inverse Propensity Score estimator, and the Doubly Robust method. Next, we present a summary of the evaluation approaches for special cases such as continuous actions and dynamic settings. We then summarize the findings on the returns to personalization across various domains, including content recommendation, advertising, and promotions. Next, we discuss the work on the intersection between personalization and welfare. We focus on four of these welfare notions that have been studied in the literature: (1) search costs, (2) privacy, (3) fairness, and (4) polarization.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"How can AI be used for personalization\"\n",
    "otherResponse = query_engine.query(prompt)\n",
    "print(otherResponse.answer)\n",
    "print()\n",
    "for paragraph in otherResponse.paragraphs_supporting_answer_directly_quoted_from_data:\n",
    "    print(paragraph)\n",
    "#for page in otherResponse.page_numbers:\n",
    "#    print(page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
